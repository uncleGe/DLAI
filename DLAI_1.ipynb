{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1st attempt at optimizing black-box function (f) using\n",
    "OpenAI's Evolution Strategies (ES) to evolve a\n",
    "Dynamically Learning Artificial Intelligence (DLAI) to run DLA,\n",
    "where the parameter distribution is a gaussian of fixed standard deviation.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "np.random.seed(0) # psuedo-randomizer seed\n",
    "# max depth with 100 rules and seed(0): \n",
    "# max depth with 100 rules and seed(1): \n",
    "# max depth with 100 rules and seed(2): 99.57\n",
    "# max depth with 100 rules and seed(3):\n",
    "# max depth with 100 rules and seed(4):\n",
    "# max depth with 100 rules and seed(5):\n",
    "# max depth with 100 rules and seed(6):\n",
    "# max depth with 100 rules and seed(7):\n",
    "# max depth with 100 rules and seed(8):\n",
    "# max depth with 100 rules and seed(9):\n",
    "\n",
    "\n",
    "\n",
    "global max_counter\n",
    "global offset\n",
    "global nrules\n",
    "nrules = 100\n",
    "\n",
    "solution = np.random.rand(nrules) # the correct weights\n",
    "w = np.random.rand(nrules) # psuedo-random list of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset: 5149\n"
     ]
    }
   ],
   "source": [
    "# print(len(w))\n",
    "# print(w)\n",
    "# print(solution)\n",
    "\n",
    "# we don't need to recompare things, so do i-1\n",
    "# but offset the reward with this number so the depth makes sense\n",
    "# e.g. for 50 rules: would be 2500 total comparisons; optimized it's 1176, so offset is 1324\n",
    "max_counter = 0\n",
    "for i in range(nrules):\n",
    "    for j in range(i-1):\n",
    "        max_counter += 1\n",
    "offset = (nrules**2) - max_counter\n",
    "print('offset: %d' % offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "npop = 50             # population size\n",
    "sigma = 0.01          # noise standard deviationN = np.random.randn(npop, 5)\n",
    "alpha = 0.001         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DLA(w):\n",
    "    # finds the nrules that are in the right order compared to all other rules\n",
    "    # not actually the depth from top\n",
    "    # so it's an all or nothing solution because rules aren't prioritized\n",
    "    depth_counter = 0    \n",
    "    for i in range(nrules):\n",
    "        for j in range(i-1):\n",
    "            if w[i] > w[j] and solution[i] > solution[j]:\n",
    "                depth_counter += 1\n",
    "            elif w[i] < w[j] and solution[i] < solution[j]:\n",
    "                depth_counter += 1\n",
    "            elif w[i] == w[j] and solution[i] == solution[j]:\n",
    "                depth_counter += 1\n",
    "    \n",
    "    reward = (depth_counter + offset) / nrules\n",
    "\n",
    "    if depth_counter == max_counter:\n",
    "        return nrules\n",
    "    else:\n",
    "        return reward\n",
    "\n",
    "def f(w):\n",
    "    \"\"\"    \n",
    "    the function we want to optimize\n",
    "    now, this is just a wrapper for DLA\n",
    "    later, this will include a NN\n",
    "    \"\"\"\n",
    "    reward = DLA(w)\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0; goal: 100; approx depth: 74.660000\n",
      "\n",
      "iter: 20; goal: 100; approx depth: 82.340000\n",
      "\n",
      "iter: 40; goal: 100; approx depth: 88.030000\n",
      "\n",
      "iter: 60; goal: 100; approx depth: 93.930000\n",
      "\n",
      "iter: 80; goal: 100; approx depth: 98.110000\n",
      "\n",
      "iter: 100; goal: 100; approx depth: 99.110000\n",
      "\n",
      "iter: 120; goal: 100; approx depth: 99.290000\n",
      "\n",
      "iter: 140; goal: 100; approx depth: 99.180000\n",
      "\n",
      "iter: 160; goal: 100; approx depth: 99.290000\n",
      "\n",
      "iter: 180; goal: 100; approx depth: 99.200000\n",
      "\n",
      "iter: 200; goal: 100; approx depth: 99.150000\n",
      "\n",
      "iter: 220; goal: 100; approx depth: 99.300000\n",
      "\n",
      "iter: 240; goal: 100; approx depth: 99.320000\n",
      "\n",
      "iter: 260; goal: 100; approx depth: 99.380000\n",
      "\n",
      "iter: 280; goal: 100; approx depth: 99.370000\n",
      "\n",
      "iter: 300; goal: 100; approx depth: 99.410000\n",
      "\n",
      "iter: 320; goal: 100; approx depth: 99.470000\n",
      "\n",
      "iter: 340; goal: 100; approx depth: 99.450000\n",
      "\n",
      "iter: 360; goal: 100; approx depth: 99.310000\n",
      "\n",
      "iter: 380; goal: 100; approx depth: 99.390000\n",
      "\n",
      "iter: 400; goal: 100; approx depth: 99.400000\n",
      "\n",
      "iter: 420; goal: 100; approx depth: 99.480000\n",
      "\n",
      "iter: 440; goal: 100; approx depth: 99.450000\n",
      "\n",
      "iter: 460; goal: 100; approx depth: 99.640000\n",
      "\n",
      "iter: 480; goal: 100; approx depth: 99.590000\n",
      "\n",
      "iter: 500; goal: 100; approx depth: 99.520000\n",
      "\n",
      "iter: 520; goal: 100; approx depth: 99.720000\n",
      "\n",
      "iter: 540; goal: 100; approx depth: 99.600000\n",
      "\n",
      "iter: 560; goal: 100; approx depth: 99.640000\n",
      "\n",
      "iter: 580; goal: 100; approx depth: 99.650000\n",
      "\n",
      "iter: 600; goal: 100; approx depth: 99.570000\n",
      "\n",
      "iter: 620; goal: 100; approx depth: 99.570000\n",
      "\n",
      "iter: 640; goal: 100; approx depth: 99.580000\n",
      "\n",
      "iter: 660; goal: 100; approx depth: 99.550000\n",
      "\n",
      "iter: 680; goal: 100; approx depth: 99.570000\n",
      "\n",
      "iter: 700; goal: 100; approx depth: 99.590000\n",
      "\n",
      "iter: 720; goal: 100; approx depth: 99.570000\n",
      "\n",
      "iter: 740; goal: 100; approx depth: 99.720000\n",
      "\n",
      "iter: 760; goal: 100; approx depth: 99.690000\n",
      "\n",
      "iter: 780; goal: 100; approx depth: 99.620000\n",
      "\n",
      "iter: 800; goal: 100; approx depth: 99.660000\n",
      "\n",
      "iter: 820; goal: 100; approx depth: 99.750000\n",
      "\n",
      "iter: 840; goal: 100; approx depth: 99.620000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the optimization\n",
    "for i in range(1001):\n",
    "    depth = f(w)\n",
    "        \n",
    "    # print current fitness of the most likely parameter setting\n",
    "    if i % 20 == 0:\n",
    "        print('iter: %d; goal: %s; approx depth: %f\\n' % \n",
    "              (i, str(nrules), depth))     \n",
    "        \n",
    "    if depth == nrules:\n",
    "        print('        :::ALL RULES SATIFIED:::')  \n",
    "        break\n",
    "\n",
    "    # initialize memory for a population of w's, and their rewards\n",
    "    N = np.random.randn(npop, nrules) # samples from a normal distribution N(0,1)\n",
    "    R = np.zeros(npop)\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "        R[j] = f(w_try) # evaluate the jittered version\n",
    "#         print('N: %s\\n\\n' % str(N))\n",
    "#     print('R: %s' % str(R))\n",
    "\n",
    "    # standardize the rewards to have a gaussian distribution\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    # perform the parameter update. The matrix multiply below\n",
    "    # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "    # where each row N[j] is weighted by A[j]\n",
    "    \n",
    "#     print('A: %s.\\n w: %s,\\n w_try: %s,\\n N.T: %s\\n\\n' %\n",
    "#         (str(A), str(w), str(w_try), str(N.T)))\n",
    "    w = w + alpha/(npop*sigma) * np.dot(N.T, A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
